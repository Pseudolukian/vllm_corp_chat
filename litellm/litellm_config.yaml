model_list:
  - model_name: llama3-8b
    litellm_params:
      model: hosted_vllm/NousResearch/Meta-Llama-3-8B-Instruct
      api_base: https://9o1qrfpuwamaiv-8000.proxy.runpod.net/v1
      api_key: "not-needed"
      num_retries: 3
      timeout: 300
  - model_name: llama3-8b
    litellm_params:
      model: hosted_vllm/NousResearch/Meta-Llama-3-8B-Instruct
      api_base: https://33pi69ozbz1sw5-8000.proxy.runpod.net/v1
      api_key: "not-needed"
      num_retries: 3
      timeout: 300      

general_settings:
  master_key: sk-1234
  set_verbose: True
  request_timeout: 600
  drop_params: True
  disable_spend_logs: True
  num_retries: 3
  cache: True
  cache_params:
    type: redis
    host: redis-cache
    port: 6379
    ttl: 3600  # Cache for 1 hour
    namespace: "litellm:cache"
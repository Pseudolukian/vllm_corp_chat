x-litellm-common: &litellm-common
  image: ghcr.io/berriai/litellm:main-latest
  restart: unless-stopped
  expose:
    - "4000"
  volumes:
    - ../litellm/litellm_config.yaml:/app/config.yaml:ro
  environment:
    - REDIS_HOST=${REDIS_HOST}
    - REDIS_PORT=${REDIS_PORT}
  networks:
    - internal
    - monitoring
  command: ["--config", "/app/config.yaml", "--port", "4000", "--detailed_debug"]
  healthcheck:
    test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:4000/health/liveliness')\" "]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 40s

services:

  # LiteLLM proxies to vLLM (3 dedicated containers for load spreading)
  litellm-1:
    <<: *litellm-common
    container_name: litellm-proxy-1

